#Importing Data
#To import data from csv file
import pandas as pd
df = pd.read_csv('yourdata.csv')
#---------------------------------------------------------------
#To import data from an Excel file, use the read_excel() method
import pandas as pd
df = pd.read_excel('filename.xlsx', sheet_name='Sheet1')
#---------------------------------------------------------------
#To import data from a SQL database, use the read_sql() method 
#and specify the connection details
import pandas as pd
import sqlite3
conn = sqlite3.connect('yourdatabase.db')
df = pd.read_sql('SELECT * FROM table_name', conn)
#---------------------------------------------------------------
#To import data from a JSON file, use the read_json() method
import pandas as pd
df = pd.read_json('filename.json')
#---------------------------------------------------------------
#To import data from an HTML page, use the read_html() method 
#and specify the URL
import pandas as pd
df_list = pd.read_html('https://www.example.com/page.html')
df = df_list[0] # Select the first DataFrame from the list

#---------------------------------------
#You can create your own data as below and save as csv or in another format
#---------------------------------------
import pandas as pd
# Create a sample DataFrame
data = {
    'id': [1, 2, 3, 4],
    'name': ['John Smith', 'Jane Doe', 'Bob Johnson', 'Alice Brown'],
    'age': [28, 35, 42, 29],
    'salary': [50000, 70000, 90000, 55000]
}
df = pd.DataFrame(data)
# Save the DataFrame to a CSV file
df.to_csv('data.csv', index=False)
#Data Summary
df.info()
df.describe()
df.head()
df.tail()
df.columns
df.index
df['col_name'].unique
df.dtypes
#Data Cleaning
import pandas as pd
#-------------------------------------
# Read data from CSV file
df = pd.read_csv('data.csv')
#-------------------------------------
# Replace missing values with the mean value of the column
df.fillna(df.mean(), inplace=True)
#-------------------------------------
# Remove duplicate rows based on the 'id' column
df.drop_duplicates(subset=['id'], inplace=True)
#-------------------------------------
# Rename columns
df.rename(columns={'name': 'full_name', 'age': 'years_old'}, inplace=True)
#-------------------------------------
# Convert 'years_old' column to integer data type
df['years_old'] = df['years_old'].astype(int)
#-------------------------------------
# Remove outliers from 'salary' column
q1 = df['salary'].quantile(0.25)
q3 = df['salary'].quantile(0.75)
iqr = q3 - q1
df = df[(df['salary'] >= q1 - 1.5 * iqr) & (df['salary'] <= q3 + 1.5 * iqr)]
#-------------------------------------
# Standardize 'full_name' column by removing leading and trailing whitespace
df['full_name'] = df['full_name'].apply(str.strip)
#-------------------------------------
# Replace all occurrences of 'Mr.' in 'full_name' column with 'Mister'
df['full_name'] = df['full_name'].str.replace('Mr.', 'Mister')

#Data manipulation
# Selecting a single row by label
df.loc[3]
# Selecting multiple rows by label
df.loc[[1, 2, 4]]
# Selecting rows and columns by label
df.loc[1:3, ['name', 'age']]
# Selecting a single row by index
df.iloc[2]
# Selecting multiple rows by index
df.iloc[[0, 2, 3]]
# Selecting rows and columns by index
df.iloc[1:3, 2:4]
# Filtering data based on a condition
df[df['age'] > 30]
# Filtering data based on multiple conditions
df[(df['age'] > 30) & (df['salary'] > 60000)]
# Sorting the DataFrame by 'age' column in ascending order
df.sort_values('age')
# Sorting the DataFrame by multiple columns
df.sort_values(['age', 'salary'], ascending=[False, True])
# Grouping data by 'age' column and computing the mean salary for each age group
df.groupby('age')['salary'].mean()
# Grouping data by 'age' and 'gender' columns and computing the maximum salary for each group
df.groupby(['age', 'gender'])['salary'].max()
# Creating two sample DataFrames
df1 = pd.DataFrame({'id': [1, 2, 3], 'name': ['John', 'Jane', 'Bob']})
df2 = pd.DataFrame({'id': [2, 3, 4], 'age': [28, 35, 42]})
# Merging the two DataFrames based on 'id' column
pd.merge(df1, df2, on='id')
#Data Visualization
# Creating a line plot of 'age' column
df.plot(x='name', y='age', kind='line')
# Creating a bar plot of 'salary' column
df.plot(x='name', y='salary', kind='bar')
# Creating a histogram of 'age' column
df.plot(y='age', kind='hist')
# Creating a scatter plot of 'age' and 'salary' columns
df.plot(x='age', y='salary', kind='scatter')
# Creating a box plot of 'salary' column
df.boxplot(column='salary')
# Creating a heat map of the correlation matrix
corr_matrix = df.corr()
import seaborn as sns
import matplotlib.pyplot as plt
sns.heatmap(corr_matrix, annot=True)
plt.show()
#Data Analysis: 
df.mean() #mean of data, can also apply on single column
df.median() #median of data
df.mode() #mode of data
df.std() #stanndard deviation of data
df.corr() #correlation of data
df.groupby('column').mean()
df.groupby(['column1', 'column2']).sum()
pd.pivot_table(df, values='column1', index='column2', columns='column3', aggfunc=np.sum)
#--------------example-----------
import pandas as pd
# Sample DataFrame
data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Alice', 'Charlie', 'David'],
        'Year': [2010, 2010, 2010, 2010, 2011, 2011, 2011],
        'Sales': [100, 200, 300, 400, 500, 600, 700]}
df = pd.DataFrame(data)
# Apply pivot_table() method to create a summary table
summary_table = pd.pivot_table(df, values='Sales', index='Name', columns='Year', aggfunc='sum')
# Print the summary table
print(summary_table)
#Data Interpretation: 
***Finally, once you have analyzed the data, you can interpret the results and draw conclusions. 
You can use the insights gained from EDA to make decisions or generate hypotheses for further analysis.***
In summary, Pandas is a powerful tool for data manipulation and analysis, and EDA is an essential step in understanding the data and making informed decisions. By using Pandas for EDA, you can quickly clean, visualize, analyze, and interpret the data, gaining valuable insights that can help you make better decisions.
